#!/usr/bin/env python3
"""
Professional No Agenda Audio Mixer - Lite Version for Initial Deployment
Server-side audio processing with simplified dependencies for faster deployment
"""

import json
import os
import sys
import requests
import tempfile
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import logging

# Basic audio processing (mock for deployment testing)
# These would be imported in production with proper dependencies
class AudioSegment:
    """Mock AudioSegment for deployment testing"""
    def __init__(self, data=None, frame_rate=44100, sample_width=2, channels=1):
        self.frame_rate = frame_rate
        self.sample_width = sample_width
        self.channels = channels
        self._duration = 30000  # 30 seconds in ms
        self.dBFS = -20.0
        self.max_dBFS = -10.0
    
    def __len__(self):
        return self._duration
    
    def __getitem__(self, key):
        # Return a new segment for slicing
        new_segment = AudioSegment()
        if isinstance(key, slice):
            start = key.start or 0
            stop = key.stop or self._duration
            new_segment._duration = max(0, stop - start)
        return new_segment
    
    def __add__(self, other):
        if isinstance(other, (int, float)):
            # Volume adjustment
            return self
        if isinstance(other, AudioSegment):
            # Concatenation - return new segment with combined duration
            new_segment = AudioSegment()
            new_segment._duration = self._duration + other._duration
            return new_segment
        return self
    
    def __sub__(self, other):
        return self  # Volume reduction
    
    def fade_in(self, duration):
        return self
    
    def fade_out(self, duration):
        return self
    
    def normalize(self):
        return self
    
    def export(self, path, format='mp3', bitrate='192k'):
        # Create a dummy file for testing
        with open(path, 'w') as f:
            f.write(f"Mock audio file - {format} at {bitrate}")
    
    @classmethod
    def from_mp3(cls, path):
        return cls()
    
    @classmethod 
    def silent(cls, duration=1000):
        segment = cls()
        segment._duration = duration
        return segment

# Mock numpy for deployment testing
class MockNumPy:
    def __init__(self):
        pass
    
    def sin(self, x):
        return [0.5] * len(x) if hasattr(x, '__len__') else 0.5
    
    def pi(self):
        return 3.14159
    
    def linspace(self, start, stop, num):
        return [start + (stop - start) * i / (num - 1) for i in range(int(num))]
    
    def log10(self, x):
        return 1.0
    
    @property
    def int16(self):
        return int

np = MockNumPy()
np.pi = 3.14159

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProfessionalAudioMixerLite:
    """Lite version of professional audio mixer for deployment testing"""
    
    def __init__(self, sample_rate: int = 44100):
        self.sample_rate = sample_rate
        self.temp_dir = None
        
        # Basic processing chains for different themes
        self.theme_settings = {
            'Best Of': {
                'eq_boost': 1.2,
                'compression': 0.8,
                'reverb_amount': 0.1,
                'description': 'Warm, polished sound'
            },
            'Media Meltdown': {
                'eq_boost': 1.5,
                'compression': 0.6,
                'reverb_amount': 0.05,
                'description': 'Aggressive, hot processing'
            },
            'Conspiracy Corner': {
                'eq_boost': 0.9,
                'compression': 0.9,
                'reverb_amount': 0.2,
                'description': 'Dark, mysterious tone'
            },
            'Donation Nation': {
                'eq_boost': 1.3,
                'compression': 0.7,
                'reverb_amount': 0.12,
                'description': 'Full, celebratory sound'
            },
            'Musical Mayhem': {
                'eq_boost': 1.1,
                'compression': 0.75,
                'reverb_amount': 0.18,
                'description': 'Creative processing'
            }
        }
    
    def setup_temp_directory(self) -> str:
        """Setup temporary directory for audio processing"""
        if not self.temp_dir:
            self.temp_dir = tempfile.mkdtemp(prefix='no_agenda_mixer_')
        return self.temp_dir
    
    def cleanup_temp_directory(self):
        """Clean up temporary files"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            import shutil
            shutil.rmtree(self.temp_dir)
            self.temp_dir = None
    
    def download_podcast_episode(self, episode_url: str) -> Optional[str]:
        """Download podcast episode to temporary file"""
        try:
            temp_dir = self.setup_temp_directory()
            temp_file = os.path.join(temp_dir, f"episode_{uuid.uuid4().hex[:8]}.mp3")
            
            logger.info(f"Downloading episode from: {episode_url}")
            
            # Download with headers to avoid blocking
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            }
            
            response = requests.get(episode_url, stream=True, timeout=300, headers=headers)
            response.raise_for_status()
            
            with open(temp_file, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            logger.info(f"Downloaded episode to: {temp_file}")
            return temp_file
            
        except Exception as e:
            logger.error(f"Failed to download episode: {e}")
            return None
    
    def load_audio_basic(self, file_path: str) -> Optional[AudioSegment]:
        """Load audio using PyDub (basic but reliable)"""
        try:
            logger.info(f"Loading audio: {file_path}")
            audio = AudioSegment.from_mp3(file_path)
            logger.info(f"Loaded audio: {len(audio)/1000:.1f}s")
            return audio
        except Exception as e:
            logger.error(f"Failed to load audio: {e}")
            return None
    
    def analyze_audio_basic(self, audio: AudioSegment) -> Dict:
        """Basic audio analysis using PyDub"""
        try:
            duration = len(audio) / 1000  # seconds
            
            # Basic analysis
            avg_dbfs = audio.dBFS
            max_dbfs = audio.max_dBFS
            
            # Simple energy analysis by splitting into chunks
            chunk_duration = 30  # 30 second chunks
            chunks = []
            
            for i in range(0, len(audio), chunk_duration * 1000):
                chunk = audio[i:i + chunk_duration * 1000]
                if len(chunk) > 5000:  # At least 5 seconds
                    chunks.append({
                        'start_time': i / 1000,
                        'duration': len(chunk) / 1000,
                        'dbfs': chunk.dBFS,
                        'max_dbfs': chunk.max_dBFS
                    })
            
            # Find high-energy chunks
            if chunks:
                avg_energy = sum(c['dbfs'] for c in chunks) / len(chunks)
                high_energy_chunks = [c for c in chunks if c['dbfs'] > avg_energy + 3]
            else:
                high_energy_chunks = []
            
            analysis = {
                'duration': duration,
                'avg_dbfs': avg_dbfs,
                'max_dbfs': max_dbfs,
                'chunks': chunks,
                'high_energy_chunks': high_energy_chunks,
                'analysis_type': 'basic'
            }
            
            logger.info(f"Basic analysis complete: {duration:.1f}s, {len(high_energy_chunks)} high-energy chunks")
            return analysis
            
        except Exception as e:
            logger.error(f"Audio analysis failed: {e}")
            return {}
    
    def intelligent_segment_selection_basic(self, audio: AudioSegment, analysis: Dict, 
                                          target_segments: int = 5) -> List[Dict]:
        """Basic intelligent segment selection"""
        try:
            duration = len(audio) / 1000
            high_energy_chunks = analysis.get('high_energy_chunks', [])
            
            selected_segments = []
            
            if high_energy_chunks and len(high_energy_chunks) >= target_segments:
                # Use high-energy chunks
                sorted_chunks = sorted(high_energy_chunks, key=lambda x: x['dbfs'], reverse=True)
                
                for i, chunk in enumerate(sorted_chunks[:target_segments]):
                    selected_segments.append({
                        'name': f'High Energy Segment {i + 1}',
                        'timestamp': chunk['start_time'],
                        'duration': min(20, chunk['duration']),  # Max 20 seconds
                        'description': f'High energy content (dBFS: {chunk["dbfs"]:.1f})',
                        'confidence': 0.8
                    })
            else:
                # Fallback: distribute evenly with some randomness
                segment_gap = duration / (target_segments + 1)
                
                for i in range(target_segments):
                    base_time = (i + 1) * segment_gap
                    # Add some randomness (Â±30 seconds)
                    random_offset = (i % 3 - 1) * 30  # Simple pseudo-random
                    start_time = max(0, min(duration - 30, base_time + random_offset))
                    
                    selected_segments.append({
                        'name': f'Content Segment {i + 1}',
                        'timestamp': start_time,
                        'duration': 15 + (i % 3) * 5,  # 15-25 seconds
                        'description': f'Selected content segment',
                        'confidence': 0.6
                    })
            
            # Sort by timestamp
            selected_segments.sort(key=lambda x: x['timestamp'])
            return selected_segments
            
        except Exception as e:
            logger.error(f"Segment selection failed: {e}")
            return self.create_fallback_segments(duration if 'duration' in locals() else 3600, target_segments)
    
    def create_fallback_segments(self, duration: float, target_segments: int) -> List[Dict]:
        """Create fallback segments when analysis fails"""
        segments = []
        segment_duration = duration / (target_segments + 1)
        
        for i in range(target_segments):
            start_time = (i + 0.5) * segment_duration
            segments.append({
                'name': f'Segment {i + 1}',
                'timestamp': start_time,
                'duration': 15,
                'description': f'Auto-selected segment {i + 1}',
                'confidence': 0.5
            })
        
        return segments
    
    def apply_basic_processing(self, audio: AudioSegment, theme: str) -> AudioSegment:
        """Apply basic processing based on theme"""
        try:
            settings = self.theme_settings.get(theme, self.theme_settings['Best Of'])
            
            # Apply basic processing
            processed = audio
            
            # Basic EQ simulation via gain adjustment
            if settings['eq_boost'] != 1.0:
                processed = processed + (20 * np.log10(settings['eq_boost']))
            
            # Basic compression simulation via dynamic range reduction
            if settings['compression'] != 1.0:
                # Simple compression: reduce loud parts
                if processed.dBFS > -12:
                    reduction = (processed.dBFS + 12) * (1 - settings['compression'])
                    processed = processed - reduction
            
            # Normalize to prevent clipping
            processed = processed.normalize()
            
            logger.info(f"Applied {theme} processing: EQ boost {settings['eq_boost']}, compression {settings['compression']}")
            return processed
            
        except Exception as e:
            logger.error(f"Processing failed: {e}")
            return audio
    
    def generate_music_placeholder(self, prompt: str, duration: int = 30) -> Optional[AudioSegment]:
        """Generate placeholder music (sine wave) for testing"""
        try:
            # Generate a simple sine wave as placeholder
            sample_rate = 44100
            frequency = 440  # A4 note
            
            # Create sine wave (mock implementation)
            samples = int(sample_rate * duration)
            # Simple mock wave data
            wave_array = [0.5] * samples
            
            # Create AudioSegment (mock implementation)
            placeholder_music = AudioSegment()
            placeholder_music._duration = duration * 1000  # Convert to ms
            
            # Apply fade in/out
            placeholder_music = placeholder_music.fade_in(1000).fade_out(1000)
            
            logger.info(f"Generated placeholder music: {duration}s")
            return placeholder_music
            
        except Exception as e:
            logger.error(f"Placeholder music generation failed: {e}")
            return None
    
    def create_professional_mix_lite(self, episode_url: str, theme: str = "Best Of", 
                                   target_duration: int = 300) -> Optional[str]:
        """Create a professional mix using lite processing"""
        try:
            logger.info(f"Creating professional mix (lite) - Theme: {theme}")
            
            # Download episode
            episode_file = self.download_podcast_episode(episode_url)
            if not episode_file:
                return None
            
            # Load audio
            audio = self.load_audio_basic(episode_file)
            if not audio:
                return None
            
            # Basic analysis
            analysis = self.analyze_audio_basic(audio)
            
            # Segment selection
            segments = self.intelligent_segment_selection_basic(audio, analysis)
            
            logger.info(f"Selected {len(segments)} segments for mixing")
            
            # Process segments
            mix_segments = []
            total_duration = 0
            
            # Add intro music placeholder
            intro_music = self.generate_music_placeholder(
                f"Intro music for {theme}", duration=5
            )
            if intro_music:
                mix_segments.append(intro_music)
                total_duration += len(intro_music) / 1000
            
            # Process each segment
            for i, segment in enumerate(segments):
                if total_duration >= target_duration:
                    break
                
                logger.info(f"Processing segment {i+1}: {segment['name']}")
                
                # Extract segment
                start_ms = int(segment['timestamp'] * 1000)
                duration_ms = int(segment['duration'] * 1000)
                end_ms = start_ms + duration_ms
                
                if start_ms < len(audio) and end_ms <= len(audio):
                    segment_audio = audio[start_ms:end_ms]
                    
                    # Apply processing
                    processed_segment = self.apply_basic_processing(segment_audio, theme)
                    
                    # Add fades
                    processed_segment = processed_segment.fade_in(300).fade_out(300)
                    
                    mix_segments.append(processed_segment)
                    total_duration += len(processed_segment) / 1000
                    
                    # Add transition between segments
                    if i < len(segments) - 1 and total_duration < target_duration - 10:
                        transition = AudioSegment.silent(duration=500)
                        mix_segments.append(transition)
                        total_duration += 0.5
            
            # Add outro music placeholder
            outro_music = self.generate_music_placeholder(
                f"Outro music for {theme}", duration=8
            )
            if outro_music:
                mix_segments.append(outro_music)
            
            # Combine segments
            if not mix_segments:
                logger.error("No segments to mix")
                return None
            
            # Mock combination - just use first segment
            final_mix = mix_segments[0]
            total_duration = sum(len(seg) for seg in mix_segments)
            final_mix._duration = total_duration
            
            # Normalize and apply final processing
            final_mix = final_mix.normalize()
            final_mix = self.apply_basic_processing(final_mix, theme)
            
            # Export
            output_path = self.export_mix(final_mix, theme)
            
            logger.info(f"Professional mix (lite) created: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Mix creation failed: {e}")
            return None
        finally:
            self.cleanup_temp_directory()
    
    def export_mix(self, audio: AudioSegment, theme: str) -> str:
        """Export the final mix"""
        try:
            temp_dir = self.setup_temp_directory()
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_theme = "".join(c for c in theme if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
            
            output_path = os.path.join(temp_dir, f'Professional_NoAgenda_{safe_theme}_{timestamp}.mp3')
            
            # Export as MP3
            audio.export(output_path, format='mp3', bitrate='192k')
            
            return output_path
            
        except Exception as e:
            logger.error(f"Export failed: {e}")
            return ""

def lambda_handler(event, context):
    """AWS Lambda handler for professional mixing (lite version)"""
    try:
        logger.info("Professional mixer (lite) Lambda handler started")
        
        # Parse request
        if event.get('httpMethod') == 'OPTIONS':
            return {
                'statusCode': 200,
                'headers': {
                    'Access-Control-Allow-Origin': '*',
                    'Access-Control-Allow-Headers': 'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token',
                    'Access-Control-Allow-Methods': 'GET,POST,PUT,DELETE,OPTIONS'
                },
                'body': ''
            }
        
        body = json.loads(event.get('body', '{}'))
        episode_url = body.get('episode_url', 'https://op3.dev/e/mp3s.nashownotes.com/NA-1779-2025-07-06-Final.mp3')
        theme = body.get('theme', 'Best Of')
        target_duration = body.get('target_duration', 120)  # Shorter for testing
        
        logger.info(f"Processing request: {episode_url}, {theme}, {target_duration}s")
        
        # Create professional mixer
        mixer = ProfessionalAudioMixerLite()
        
        # Create mix
        output_path = mixer.create_professional_mix_lite(episode_url, theme, target_duration)
        
        if output_path:
            return {
                'statusCode': 200,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'status': 'success',
                    'mix_path': output_path,
                    'theme': theme,
                    'message': 'Professional mix (lite) created successfully',
                    'processing_type': 'lite_version',
                    'duration': target_duration
                })
            }
        else:
            return {
                'statusCode': 500,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'status': 'error',
                    'message': 'Mix creation failed'
                })
            }
    
    except Exception as e:
        logger.error(f"Lambda handler error: {e}")
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'status': 'error',
                'message': str(e),
                'type': 'lambda_error'
            })
        }

if __name__ == '__main__':
    """Command line usage for testing"""
    mixer = ProfessionalAudioMixerLite()
    
    episode_url = "https://op3.dev/e/mp3s.nashownotes.com/NA-1779-2025-07-06-Final.mp3"
    theme = sys.argv[1] if len(sys.argv) > 1 else "Best Of"
    
    output_path = mixer.create_professional_mix_lite(episode_url, theme, 120)
    
    if output_path:
        print(f"ð Professional mix (lite) created: {output_path}")
    else:
        print("â Mix creation failed")